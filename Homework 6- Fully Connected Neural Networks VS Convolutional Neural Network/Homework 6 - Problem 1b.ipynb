{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8620c9c5-4848-4be7-ad8b-5b9221f7d889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Sanaz Hosseini\"- University of North Carolina at Charlotte\n",
    "# Introduction to Machine Learning Class - Instructor: Prof. Hamed Tabkhi\n",
    "# Fully Connected Neural Networks VS Convolutional Neural Network\n",
    "# Homework 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74445719-221b-4460-9202-03067fc1af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2839935d-2ee0-4369-9bff-edb7f2723ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "data_path = '../data-unversioned/p1ch7/'\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ed33f0b-dfe6-40e9-8d60-87d79911afb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5536eec-1f23-4bb2-b63f-d0fcb1d38da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37f6f9f3-2dfa-477c-bbb1-9e9ec6679a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "n_out = 10\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, n_out),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "606728d2-9ea5-42e1-bbd6-fc359ea6baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91ebb4b8-b0f2-4501-958e-58a04fb7034e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1085, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = cifar10[0]\n",
    "\n",
    "out = model(img.view(-1).unsqueeze(0))\n",
    "\n",
    "loss(out, torch.tensor([label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "289023f6-1f8f-4a31-8d1d-25f397db0d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-10 18:36:07.859248 Epoch 1, Training loss 1.673237381383891\n",
      "2022-12-10 18:38:56.135501 Epoch 10, Training loss 0.9060790273539551\n",
      "2022-12-10 18:42:07.764159 Epoch 20, Training loss 0.541906619030039\n",
      "2022-12-10 18:45:14.249325 Epoch 30, Training loss 0.37347608223519363\n",
      "2022-12-10 18:48:23.054310 Epoch 40, Training loss 0.2783795592882444\n",
      "2022-12-10 18:51:30.359507 Epoch 50, Training loss 0.249001441918828\n",
      "2022-12-10 18:54:36.339435 Epoch 60, Training loss 0.20147149199548434\n",
      "2022-12-10 18:57:43.594684 Epoch 70, Training loss 0.18866344788076017\n",
      "2022-12-10 19:00:51.242258 Epoch 80, Training loss 0.16184990525202791\n",
      "2022-12-10 19:03:58.034996 Epoch 90, Training loss 0.14581574769774\n",
      "2022-12-10 19:07:08.279758 Epoch 100, Training loss 0.14347260941982345\n",
      "2022-12-10 19:10:27.905223 Epoch 110, Training loss 0.13713459560797667\n",
      "2022-12-10 19:13:37.920145 Epoch 120, Training loss 0.11866026777473976\n",
      "2022-12-10 19:16:45.750114 Epoch 130, Training loss 0.1083180743809718\n",
      "2022-12-10 19:19:53.230066 Epoch 140, Training loss 0.1098455930390107\n",
      "2022-12-10 19:23:01.450267 Epoch 150, Training loss 0.1079516568679072\n",
      "2022-12-10 19:26:08.555566 Epoch 160, Training loss 0.11436265009164195\n",
      "2022-12-10 19:29:16.890283 Epoch 170, Training loss 0.10938743590180765\n",
      "2022-12-10 19:32:25.030448 Epoch 180, Training loss 0.09411029763671015\n",
      "2022-12-10 19:35:32.025833 Epoch 190, Training loss 0.09832712724466053\n",
      "2022-12-10 19:38:39.075686 Epoch 200, Training loss 0.0928311875069757\n",
      "2022-12-10 19:41:47.641046 Epoch 210, Training loss 0.06999624356751175\n",
      "2022-12-10 19:44:35.381038 Epoch 220, Training loss 0.08811337941577342\n",
      "2022-12-10 19:46:35.910992 Epoch 230, Training loss 0.08275644285907305\n",
      "2022-12-10 19:48:21.796022 Epoch 240, Training loss 0.08141211696724465\n",
      "2022-12-10 19:50:07.692889 Epoch 250, Training loss 0.09082476504165214\n",
      "2022-12-10 19:51:53.561057 Epoch 260, Training loss 0.10098847244056197\n",
      "2022-12-10 19:53:39.341216 Epoch 270, Training loss 0.0886492745468223\n",
      "2022-12-10 19:55:36.011064 Epoch 280, Training loss 0.068371026166053\n",
      "2022-12-10 19:57:30.591116 Epoch 290, Training loss 0.07018032859571849\n",
      "2022-12-10 19:59:17.231485 Epoch 300, Training loss 0.08259508060236515\n"
     ]
    }
   ],
   "source": [
    "import datetime  \n",
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10),\n",
    "            nn.LogSoftmax(dim=1))\n",
    "\n",
    "model.to(device)\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.NLLLoss()\n",
    "n_epochs = 300\n",
    "\n",
    "for epoch in range(1, n_epochs + 1): \n",
    "        loss_train = 0.0\n",
    "        training_start_time = time.time()\n",
    "        for imgs, labels in train_loader:  \n",
    "            imgs=imgs.to(device)\n",
    "            labels=labels.to(device)\n",
    "            outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "            loss = loss_fn(outputs, labels) \n",
    "            \n",
    "            optimizer.zero_grad() \n",
    "            loss.backward()  \n",
    "            optimizer.step()  \n",
    "            loss_train += loss.item() \n",
    "            \n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "694b80b8-e885-4c9c-a8b2-6393cc8c5577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.986940\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs=imgs.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "       \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61f59190-b984-47f4-87a2-736d46d29f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-10 20:23:26.505723 Epoch 1, Training loss 1.6803107173241618\n",
      "2022-12-10 20:25:06.312002 Epoch 10, Training loss 0.8693386975990232\n",
      "2022-12-10 20:26:57.031874 Epoch 20, Training loss 0.4812492913640369\n",
      "2022-12-10 20:28:48.256844 Epoch 30, Training loss 0.330466573248091\n",
      "2022-12-10 20:30:38.902300 Epoch 40, Training loss 0.2644229508993571\n",
      "2022-12-10 20:32:29.602312 Epoch 50, Training loss 0.21903069929727126\n",
      "2022-12-10 20:34:20.904219 Epoch 60, Training loss 0.18474198846846743\n",
      "2022-12-10 20:36:12.032271 Epoch 70, Training loss 0.1722965449454439\n",
      "2022-12-10 20:38:03.206550 Epoch 80, Training loss 0.14638836496471502\n",
      "2022-12-10 20:39:54.957567 Epoch 90, Training loss 0.155758059071496\n",
      "2022-12-10 20:41:46.504041 Epoch 100, Training loss 0.1280352481250244\n",
      "2022-12-10 20:43:41.212320 Epoch 110, Training loss 0.13180096306816658\n",
      "2022-12-10 20:45:35.642286 Epoch 120, Training loss 0.12571092947627968\n",
      "2022-12-10 20:47:28.342278 Epoch 130, Training loss 0.13017092507434985\n",
      "2022-12-10 20:49:21.077769 Epoch 140, Training loss 0.12048226427045695\n",
      "2022-12-10 20:51:13.692433 Epoch 150, Training loss 0.12757415348104775\n",
      "2022-12-10 20:53:05.862641 Epoch 160, Training loss 0.09735574582835797\n",
      "2022-12-10 20:55:03.442303 Epoch 170, Training loss 0.08806027761726987\n",
      "2022-12-10 20:57:08.062618 Epoch 180, Training loss 0.1017551007613604\n",
      "2022-12-10 20:59:00.322588 Epoch 190, Training loss 0.10515380525526673\n",
      "2022-12-10 21:00:53.272671 Epoch 200, Training loss 0.10678738178484706\n",
      "2022-12-10 21:02:45.574734 Epoch 210, Training loss 0.10476319071955828\n",
      "2022-12-10 21:04:38.232807 Epoch 220, Training loss 0.10070607145600122\n",
      "2022-12-10 21:06:30.742811 Epoch 230, Training loss 0.09445290874074908\n",
      "2022-12-10 21:08:22.927833 Epoch 240, Training loss 0.10607089271323512\n",
      "2022-12-10 21:10:16.463111 Epoch 250, Training loss 0.10098495270761275\n",
      "2022-12-10 21:12:10.698662 Epoch 260, Training loss 0.0898524134759374\n",
      "2022-12-10 21:14:03.769248 Epoch 270, Training loss 0.0809683889179407\n",
      "2022-12-10 21:16:00.348414 Epoch 280, Training loss 0.09901448197593904\n",
      "2022-12-10 21:17:54.983590 Epoch 290, Training loss 0.06830760666230802\n",
      "2022-12-10 21:19:50.143156 Epoch 300, Training loss 0.08538902841070603\n"
     ]
    }
   ],
   "source": [
    "import datetime  \n",
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "            nn.LogSoftmax(dim=1))\n",
    "\n",
    "model.to(device)\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.NLLLoss()\n",
    "n_epochs = 300\n",
    "\n",
    "for epoch in range(1, n_epochs + 1): \n",
    "        loss_train = 0.0\n",
    "        training_start_time = time.time()\n",
    "        for imgs, labels in train_loader:  \n",
    "            imgs=imgs.to(device)\n",
    "            labels=labels.to(device)\n",
    "            outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "            loss = loss_fn(outputs, labels) \n",
    "            \n",
    "            optimizer.zero_grad() \n",
    "            loss.backward()  \n",
    "            optimizer.step()  \n",
    "            loss_train += loss.item() \n",
    "            \n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99295bab-c1eb-4792-bc97-0100aeb4e944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.992920\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs=imgs.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "       \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df92fc9-7626-4ef8-8562-dcfae268329f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
