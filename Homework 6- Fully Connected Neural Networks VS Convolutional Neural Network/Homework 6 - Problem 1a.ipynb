{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e6cbf5-8d33-4119-9cf9-6c8804960b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Sanaz Hosseini\"- University of North Carolina at Charlotte\n",
    "# Introduction to Machine Learning Class - Instructor: Prof. Hamed Tabkhi\n",
    "# Fully Connected Neural Networks VS Convolutional Neural Network\n",
    "# Homework 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74445719-221b-4460-9202-03067fc1af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2839935d-2ee0-4369-9bff-edb7f2723ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "data_path = '../data-unversioned/p1ch7/'\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ed33f0b-dfe6-40e9-8d60-87d79911afb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5536eec-1f23-4bb2-b63f-d0fcb1d38da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37f6f9f3-2dfa-477c-bbb1-9e9ec6679a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "n_out = 10\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_out)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d52a79e-8a6d-4c83-9fda-88b11cdc5fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "606728d2-9ea5-42e1-bbd6-fc359ea6baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91ebb4b8-b0f2-4501-958e-58a04fb7034e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0785, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs, label = cifar10[0]\n",
    "\n",
    "out = model(img.view(-1).unsqueeze(0))\n",
    "\n",
    "loss(out, torch.tensor([label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "289023f6-1f8f-4a31-8d1d-25f397db0d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-10 13:45:07.376976 Epoch 1, Training loss 1.7207147134539416\n",
      "2022-12-10 13:50:25.869525 Epoch 10, Training loss 1.0912875848657944\n",
      "2022-12-10 13:58:16.715891 Epoch 20, Training loss 0.7841284063923389\n",
      "2022-12-10 14:06:47.623993 Epoch 30, Training loss 0.5789946576251703\n",
      "2022-12-10 14:16:00.761149 Epoch 40, Training loss 0.4558614944024464\n",
      "2022-12-10 14:24:58.874136 Epoch 50, Training loss 0.41936354565403194\n",
      "2022-12-10 14:33:41.515398 Epoch 60, Training loss 0.38958945333638495\n",
      "2022-12-10 14:42:01.329633 Epoch 70, Training loss 0.3121620452607913\n",
      "2022-12-10 14:49:08.410329 Epoch 80, Training loss 0.32396783360191966\n",
      "2022-12-10 14:56:13.827367 Epoch 90, Training loss 0.29715627053623916\n",
      "2022-12-10 15:04:02.463644 Epoch 100, Training loss 0.32481246206300846\n",
      "2022-12-10 15:12:07.430403 Epoch 110, Training loss 0.30454796869480444\n",
      "2022-12-10 15:20:36.741313 Epoch 120, Training loss 0.2859015967421498\n",
      "2022-12-10 15:27:43.439637 Epoch 130, Training loss 0.2919010809258572\n",
      "2022-12-10 15:34:45.511807 Epoch 140, Training loss 0.2895126102238094\n",
      "2022-12-10 15:42:14.720969 Epoch 150, Training loss 0.2834825932287642\n",
      "2022-12-10 15:49:18.295939 Epoch 160, Training loss 0.24893469194608778\n",
      "2022-12-10 15:56:08.337585 Epoch 170, Training loss 0.30473702768701033\n",
      "2022-12-10 16:03:11.380606 Epoch 180, Training loss 0.2826825721668844\n",
      "2022-12-10 16:10:05.389361 Epoch 190, Training loss 0.280476010770857\n",
      "2022-12-10 16:17:04.563303 Epoch 200, Training loss 0.21191529763439265\n",
      "2022-12-10 16:24:16.224928 Epoch 210, Training loss 0.2795688009791403\n",
      "2022-12-10 16:31:06.186172 Epoch 220, Training loss 0.24797071476341026\n",
      "2022-12-10 16:37:59.709441 Epoch 230, Training loss 0.2711588168525937\n",
      "2022-12-10 16:45:19.166181 Epoch 240, Training loss 0.24998191867823383\n",
      "2022-12-10 16:52:42.787683 Epoch 250, Training loss 0.21650938201902448\n",
      "2022-12-10 16:59:53.629911 Epoch 260, Training loss 0.22782277527158354\n",
      "2022-12-10 17:06:57.588151 Epoch 270, Training loss 0.2562023526222392\n",
      "2022-12-10 17:13:47.372026 Epoch 280, Training loss 0.18717663341303206\n",
      "2022-12-10 17:20:44.403957 Epoch 290, Training loss 0.21737511915412566\n",
      "2022-12-10 17:28:03.610334 Epoch 300, Training loss 0.2165234592466115\n"
     ]
    }
   ],
   "source": [
    "import datetime  \n",
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.LogSoftmax(dim=1))\n",
    "\n",
    "model.to(device)\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.NLLLoss()\n",
    "n_epochs = 300\n",
    "\n",
    "for epoch in range(1, n_epochs + 1): \n",
    "        loss_train = 0.0\n",
    "        training_start_time = time.time()\n",
    "        for imgs, labels in train_loader:  \n",
    "            imgs=imgs.to(device)\n",
    "            labels=labels.to(device)\n",
    "            outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "            loss = loss_fn(outputs, labels) \n",
    "            \n",
    "            optimizer.zero_grad() \n",
    "            loss.backward()  \n",
    "            optimizer.step()  \n",
    "            loss_train += loss.item() \n",
    "            \n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "694b80b8-e885-4c9c-a8b2-6393cc8c5577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.967940\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs=imgs.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac5cf04-9aaf-4419-a16b-d87249b46647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
