{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76c85df4-6b46-41f2-906e-607f25d60af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Sanaz Hosseini\"- University of North Carolina at Charlotte\n",
    "# Introduction to Machine Learning Class - Instructor: Prof. Hamed Tabkhi\n",
    "# Fully Connected Neural Networks VS Convolutional Neural Network\n",
    "# Homework 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "830cdd12-18c9-4608-9043-7095d5e78c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d2e867a-07b6-48d8-8712-2244dc86cc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8425ab9-66b0-4898-adab-5612bc6d036f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "data_path = '../data-unversioned/p1ch7/'\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e2eb509-e459-454e-896a-316bf4389caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "182c2a67-d553-475c-b063-ddef48f637d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU!\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Running on the GPU!\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9feca7a-705b-4e84-a082-501972ee8804",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e7eae8e-2de1-4934-8f02-7fb7e20680d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_model = nn.Sequential(\n",
    "            nn.Linear(3072, 1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26302522-67c4-43b2-96f1-b06c268e3cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3737474, [3145728, 1024, 524288, 512, 65536, 128, 256, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numel_list = [p.numel()\n",
    "              for p in connected_model.parameters()\n",
    "              if p.requires_grad == True]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad47c3cb-30a0-4e85-ba0a-ecdc8bcb0761",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model = nn.Sequential(\n",
    "                nn.Linear(3072, 512),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(512, 2),\n",
    "                nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb267b12-8627-401b-aa54-6760778dd595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1024, 3072]), torch.Size([1024]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(3072, 1024)\n",
    "\n",
    "linear.weight.shape, linear.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60cd32a9-c9a6-4b7a-b612-1e65944e827f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv2d(3, 16, kernel_size=3) # <1>\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbe9929b-a514-421d-83f0-74b1a85c2050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 3, 3, 3]), torch.Size([16]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight.shape, conv.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bce5081-0983-4b46-bde0-013f5dd7ab71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 32, 32]), torch.Size([1, 16, 30, 30]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, _ = cifar10[0]\n",
    "output = conv(img.unsqueeze(0))\n",
    "img.unsqueeze(0).shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bb34ca0-6879-4aa9-bb16-4b62cdc3c19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 32, 32]), torch.Size([1, 3, 16, 16]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = nn.MaxPool2d(2)\n",
    "output = pool(img.unsqueeze(0))\n",
    "\n",
    "img.unsqueeze(0).shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "028a82ac-bf91-4d9a-b062-432fbaf53113",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
    "            nn.BatchNorm2d(64),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "            nn.BatchNorm2d(128),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "            nn.BatchNorm2d(256),\n",
    "\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(256*4*4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e215bb2f-f8b7-4335-8e70-fc17d46c5a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5852234,\n",
       " [864,\n",
       "  32,\n",
       "  18432,\n",
       "  64,\n",
       "  64,\n",
       "  64,\n",
       "  73728,\n",
       "  128,\n",
       "  147456,\n",
       "  128,\n",
       "  128,\n",
       "  128,\n",
       "  294912,\n",
       "  256,\n",
       "  589824,\n",
       "  256,\n",
       "  256,\n",
       "  256,\n",
       "  4194304,\n",
       "  1024,\n",
       "  524288,\n",
       "  512,\n",
       "  5120,\n",
       "  10])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net().to(device)\n",
    "model = net\n",
    "\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06e1325f-6c67-46f5-ad46-c8429707d5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime  \n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader: \n",
    "            imgs=imgs.to(device)\n",
    "            labels=labels.to(device)\n",
    "            outputs = model(imgs)  \n",
    "            \n",
    "            loss = loss_fn(outputs, labels)  \n",
    "\n",
    "            optimizer.zero_grad()  # <6>            \n",
    "            loss.backward()  # <7>\n",
    "            \n",
    "            optimizer.step()  # <8>\n",
    "\n",
    "            loss_train += loss.item()  # <9>\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84658e4c-4d50-44cf-bc4f-d0af292bc01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-10 15:54:41.003385 Epoch 1, Training loss 1.1592650747360171\n",
      "2022-12-10 15:57:55.786136 Epoch 10, Training loss 0.07699277367585165\n",
      "2022-12-10 16:01:22.965263 Epoch 20, Training loss 0.06349975369101607\n",
      "2022-12-10 16:04:49.576098 Epoch 30, Training loss 0.029843203130882043\n",
      "2022-12-10 16:08:16.784748 Epoch 40, Training loss 0.030490410564242877\n",
      "2022-12-10 16:11:51.434555 Epoch 50, Training loss 0.023702063835747227\n",
      "2022-12-10 16:15:29.100043 Epoch 60, Training loss 0.018408756404824717\n",
      "2022-12-10 16:18:47.547477 Epoch 70, Training loss 0.014594730562624184\n",
      "2022-12-10 16:22:06.759994 Epoch 80, Training loss 0.016229879716689672\n",
      "2022-12-10 16:25:28.781876 Epoch 90, Training loss 0.014457600243983945\n",
      "2022-12-10 16:28:52.585173 Epoch 100, Training loss 0.012851612315699645\n",
      "2022-12-10 16:32:16.198814 Epoch 110, Training loss 0.01742189304811378\n",
      "2022-12-10 16:37:36.273111 Epoch 120, Training loss 0.013994205788866817\n",
      "2022-12-10 16:40:53.982988 Epoch 130, Training loss 0.012684865663978737\n",
      "2022-12-10 16:44:11.892620 Epoch 140, Training loss 0.007993385350625656\n",
      "2022-12-10 16:47:32.731908 Epoch 150, Training loss 0.009608487012346774\n",
      "2022-12-10 16:50:54.726938 Epoch 160, Training loss 0.009399831374220223\n",
      "2022-12-10 17:14:23.172658 Epoch 170, Training loss 0.007749262905297119\n",
      "2022-12-10 17:17:42.025880 Epoch 180, Training loss 0.014108278243135614\n",
      "2022-12-10 17:21:02.259662 Epoch 190, Training loss 0.010152523210679098\n",
      "2022-12-10 17:24:20.612482 Epoch 200, Training loss 0.011424454256303663\n",
      "2022-12-10 17:27:36.130604 Epoch 210, Training loss 0.0126225298211536\n",
      "2022-12-10 17:30:41.976305 Epoch 220, Training loss 0.007395432245196973\n",
      "2022-12-10 17:33:44.338294 Epoch 230, Training loss 0.010254681828187022\n",
      "2022-12-10 17:36:52.412980 Epoch 240, Training loss 0.007635084104925114\n",
      "2022-12-10 17:39:53.578349 Epoch 250, Training loss 0.010230951502662728\n",
      "2022-12-10 17:42:57.822948 Epoch 260, Training loss 0.013588072481998252\n",
      "2022-12-10 17:46:00.413031 Epoch 270, Training loss 0.010539959873026944\n",
      "2022-12-10 17:49:04.888368 Epoch 280, Training loss 0.01021190413026509\n",
      "2022-12-10 17:52:08.851247 Epoch 290, Training loss 0.008227650496994645\n",
      "2022-12-10 17:55:16.528193 Epoch 300, Training loss 0.004993561869313122\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64, shuffle=True)  \n",
    "\n",
    "model = Net().to(device)  \n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3) \n",
    "loss_fn = nn.CrossEntropyLoss()  #  <4>\n",
    "\n",
    "training_loop(  \n",
    "    n_epochs = 300,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7260021e-a8c1-4d30-8046-6dd262c60218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 1.00\n",
      "Accuracy val: 0.83\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():  # <1>\n",
    "            for imgs, labels in loader:\n",
    "                imgs=imgs.to(device)\n",
    "                labels=labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
    "                total += labels.shape[0]  # <3>\n",
    "                correct += int((predicted == labels).sum())  # <4>\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "\n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdb3d28-e160-43b6-9885-f8d7fb59d214",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
